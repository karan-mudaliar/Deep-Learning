{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karan-mudaliar/Deep-Learning/blob/main/HW2_3_DenoisingAutoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a188be37",
      "metadata": {
        "id": "a188be37"
      },
      "source": [
        "This can be run [run on Google Colab using this link](https://colab.research.google.com/github/CS7150/CS7150-Homework-2/blob/main/HW2_3_DenoisingAutoencoder.ipynb)\n",
        "\n",
        "<font size='6'>**Homework 2.3: Denoising Autoencoder (DAE)**</font>\n",
        "\n",
        "Denoising Autoencoders are a class of autoencoders where we attempt to remove noise from a customized data. Note the emphasis on the word `customized`. Given that we train a DAE on a particular dataset, it is optimized to remove dataset from the samples of that dataset only and will not be suitable on other dataset samples. (Want to learn more on EBM models? Read more on [Energy Based Models](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf))\n",
        "\n",
        "So let's code a simple DAE and explore it's functioning !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e4af49",
      "metadata": {
        "id": "52e4af49"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader,random_split,Subset\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ad4fe87",
      "metadata": {
        "id": "9ad4fe87"
      },
      "source": [
        "## Downloading the dataset\n",
        "This can be done in few ways:\n",
        "1. Downloading from  torch library (preferred)\n",
        "2. From the official portal [here](http://yann.lecun.com/exdb/mnist/).\n",
        "\n",
        "Note: If you download from the official portal, you need to write your custom wrapper to read the data into desired variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d29bd07",
      "metadata": {
        "id": "7d29bd07"
      },
      "outputs": [],
      "source": [
        "# downloading mnist into folder\n",
        "data_dir = 'data' # make sure that this folder is created in your working dir\n",
        "# transform the PIL images to tensor using torchvision.transform.toTensor method\n",
        "train_data = torchvision.datasets.MNIST(data_dir, train=True, download=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))\n",
        "test_data  = torchvision.datasets.MNIST(data_dir, train=False, download=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))\n",
        "print(f'Datatype of the dataset object: {type(train_data)}')\n",
        "# check the length of dataset\n",
        "print(f'Number of samples in training data: {len(train_data)}')\n",
        "print(f'Number of samples in test data: {len(test_data)}')\n",
        "# Check the format of dataset\n",
        "print(f'Foramt of the dataset: \\n {train_data}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99254a83",
      "metadata": {
        "id": "99254a83"
      },
      "source": [
        "## Displaying the loaded dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc391699",
      "metadata": {
        "id": "bc391699"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(train_data[i][0][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Class Label: {}\".format(train_data[i][1]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bc3accb",
      "metadata": {
        "id": "6bc3accb"
      },
      "source": [
        "If your code is running so far without any errors, you are all set to start building the network and train it!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "809d0f8f",
      "metadata": {
        "id": "809d0f8f"
      },
      "source": [
        "## Building a DAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c60adc",
      "metadata": {
        "id": "e5c60adc"
      },
      "outputs": [],
      "source": [
        "class dae(nn.Module):\n",
        "    def __init__(self, inp_dim = 28*28, device='cuda'):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(inp_dim,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,8)\n",
        "            )\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(8,64),\n",
        "            nn.Linear(64,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,28*28),\n",
        "            nn.Sigmoid(),\n",
        "            )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        encoded = self.encoder(inp)\n",
        "        reconstructed = self.decoder(encoded)\n",
        "        return reconstructed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3296402",
      "metadata": {
        "id": "c3296402"
      },
      "source": [
        "## Function to add noise to data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f5d4c5b",
      "metadata": {
        "id": "7f5d4c5b"
      },
      "outputs": [],
      "source": [
        "def add_noise(inp,noise_factor=0.3):\n",
        "    noise = torch.rand(inp.shape) # Creating a noise in the same shape as input\n",
        "    noisy_image = inp + noise\n",
        "    return noisy_image, noise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "236d887b",
      "metadata": {
        "id": "236d887b"
      },
      "source": [
        "## Functions to train and test the DAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fc5f48",
      "metadata": {
        "id": "18fc5f48"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_dae(model, input_dim, device, dataloader, loss_fn, optimizer,noise_factor=0.3):\n",
        "    # Set the model to train\n",
        "    model.train()\n",
        "    # Initiate a loss monitor\n",
        "    train_loss = []\n",
        "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning and not supervised classification)\n",
        "    for images, labels in dataloader: # the variable `labels` willbe used for customised training\n",
        "        # Add noise to images\n",
        "        noisy_images, actual_noise = add_noise(images, noise_factor)\n",
        "        # move the data to preferred device GPU/CPU\n",
        "        images = images.to(device)\n",
        "        noisy_images = noisy_images.to(device)\n",
        "        # send the noisy data through DAE to denoise\n",
        "        # reshape images to fit the FC layers\n",
        "        noisy_images = torch.reshape(noisy_images,input_dim)\n",
        "        images = torch.reshape(images,input_dim)\n",
        "\n",
        "        denoised_images = model(noisy_images)\n",
        "\n",
        "        loss = loss_fn(denoised_images, images)\n",
        "        # Backward pass (back propagation)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    return np.mean(train_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9384d5d",
      "metadata": {
        "id": "a9384d5d"
      },
      "outputs": [],
      "source": [
        "# Testing Function\n",
        "def test_dae(model, input_dim, device, dataloader, loss_fn,noise_factor=0.3):\n",
        "    # Set evaluation mode for model\n",
        "    model.eval()\n",
        "    with torch.no_grad(): # No need to track the gradients\n",
        "        # Define the lists to store the outputs for each batch\n",
        "        predicted = []\n",
        "        actual = []\n",
        "        for images, labels in dataloader:\n",
        "            # Add noise to images\n",
        "            noisy_images, actual_noise = add_noise(images, noise_factor)\n",
        "            # move the data to preferred device GPU/CPU\n",
        "            images = images.to(device)\n",
        "            noisy_images = noisy_images.to(device)\n",
        "            # send the noisy data through DAE to denoise\n",
        "            # reshape the data to fit FC layers\n",
        "            noisy_images = torch.reshape(noisy_images,input_dim)\n",
        "            images = torch.reshape(images,input_dim)\n",
        "            # denoise the image\n",
        "            denoised_images = model(noisy_images)\n",
        "            # Append the network output and the original image to the lists\n",
        "            predicted.append(denoised_images.cpu())\n",
        "            actual.append(images.cpu())\n",
        "        # Create a single tensor with all the values in the lists\n",
        "        predicted = torch.cat(predicted)\n",
        "        actual = torch.cat(actual)\n",
        "        # Evaluate global loss\n",
        "        val_loss = loss_fn(predicted, actual)\n",
        "    return val_loss.data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c94b356e",
      "metadata": {
        "id": "c94b356e"
      },
      "source": [
        "## Function to plot results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279efc17",
      "metadata": {
        "id": "279efc17"
      },
      "outputs": [],
      "source": [
        "def plot_dae_inference(model, test_dataset, n=10, noise_factor=0.3, save_to_file=''):\n",
        "    plt.figure(figsize=(15,5))\n",
        "    labels = test_dataset.targets.numpy()\n",
        "    idx = {i:np.where(labels==i)[0][0] for i in range(n)}\n",
        "    for i in range(n):\n",
        "\n",
        "        ax = plt.subplot(3,n,i+1)\n",
        "        ax.set(facecolor = \"white\")\n",
        "        image = test_dataset[idx[i]][0].unsqueeze(0)\n",
        "        noisy_images, _ = add_noise(image, noise_factor)\n",
        "        noisy_images = noisy_images.to(device)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            denoised_images  = model(torch.reshape(noisy_images,(-1,28*28)))\n",
        "            denoised_images = torch.reshape(denoised_images,(-1,1,28,28))\n",
        "\n",
        "        plt.imshow(image.cpu().squeeze().numpy(), cmap='gray')\n",
        "        ax.axis('off')\n",
        "        if i == n//2:\n",
        "            ax.set_title('Actual Image')\n",
        "        ax = plt.subplot(3, n, i + 1 + n)\n",
        "        plt.imshow(noisy_images.cpu().squeeze().numpy(), cmap='gray')\n",
        "        ax.axis('off')\n",
        "        if i == n//2:\n",
        "            ax.set_title('Corrupted Image')\n",
        "\n",
        "        ax = plt.subplot(3, n, i + 1 + n + n)\n",
        "        plt.imshow(denoised_images.cpu().squeeze().numpy(), cmap='gray')\n",
        "        ax.axis('off')\n",
        "        if i == n//2:\n",
        "            ax.set_title('Denoised Image')\n",
        "    plt.subplots_adjust(left=0.1,\n",
        "                    bottom=0.1,\n",
        "                    right=0.7,\n",
        "                    top=0.9,\n",
        "                    wspace=0.3,\n",
        "                    hspace=0.3)\n",
        "    if len(save_to_file) != 0:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_to_file, facecolor='white',transparent=False)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b6aea08",
      "metadata": {
        "id": "3b6aea08"
      },
      "source": [
        "## Initializing the models, optimizer and loss function. Load the model to CPU/GPU device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ac4694",
      "metadata": {
        "id": "39ac4694"
      },
      "outputs": [],
      "source": [
        "### Set the random seed for reproducible results\n",
        "torch.manual_seed(1234)\n",
        "# Choosing a device based on the env and torch setup\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f'Selected device: {device}')\n",
        "\n",
        "\n",
        "### Initialize the network\n",
        "\n",
        "model = dae(inp_dim=28*28, device=device)\n",
        "# Move both the encoder and the decoder to the selected device\n",
        "model.to(device)\n",
        "\n",
        "params_to_optimize = [\n",
        "    {'params': model.parameters()}\n",
        "]\n",
        "### Define the loss function\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "### Define an optimizer (both for the encoder and the decoder!)\n",
        "lr= 0.001\n",
        "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3db059b",
      "metadata": {
        "id": "e3db059b"
      },
      "source": [
        "Now let's train the model. Before that, let's test out the EBM theory we were talking about in the introduction. In the below code, we are going to show only certain classes to the model while training to see it's performance generalisation. To explain clearly, let's assume we train the model on samples with 0,1,2,3,4 classes. Now let's see how the model performs on data from the rest of the classes like 5,6,7,8,9. This will be cool to visualise!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ccd7c1",
      "metadata": {
        "scrolled": true,
        "id": "49ccd7c1"
      },
      "outputs": [],
      "source": [
        "### Intialize dataloaders\n",
        "val_split = .2\n",
        "batch_size=256\n",
        "\n",
        "# A trick to include only certain samples in the training. We are showing only samples 0,1,2,3,4 to the DAE while training.\n",
        "include_samples = [0,1,2,3,4] # to ensure customised training\n",
        "\n",
        "indices = [idx for idx, target in enumerate(train_data.targets) if target in include_samples]\n",
        "train_data_new = Subset(train_data, indices) # Only include samples\n",
        "n_train_samples = len(train_data_new)\n",
        "train_data_, val_data = random_split(train_data_new, [int(n_train_samples*(1-val_split)), int(n_train_samples*val_split)+1])\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data_, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "### Training cycle\n",
        "noise_factor = 0.3\n",
        "num_epochs = 30\n",
        "history={'train_loss':[],'val_loss':[]}\n",
        "\n",
        "print('DAE training started')\n",
        "for epoch in range(num_epochs):\n",
        "    ### Training\n",
        "    print(f'---------------------------------------------Epoch {epoch+1}/{num_epochs}---------------------------------------------')\n",
        "    train_loss=train_dae(\n",
        "        model=model,\n",
        "        input_dim=(-1,28*28),\n",
        "        device=device,\n",
        "        dataloader=train_loader,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optim,noise_factor=noise_factor)\n",
        "    ### Validation  (use the testing function)\n",
        "    val_loss = test_dae(\n",
        "        model=model,\n",
        "        input_dim=(-1,28*28),\n",
        "        device=device,\n",
        "        dataloader=valid_loader,\n",
        "        loss_fn=loss_fn,noise_factor=noise_factor)\n",
        "    # Print Validationloss\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    print('\\n \\t \\t \\t train loss {:.3f} \\t val loss {:.3f}'.format(train_loss,val_loss))\n",
        "    plot_dae_inference(model,test_dataset=test_data,noise_factor=noise_factor)\n",
        "print('DAE training done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23264632",
      "metadata": {
        "id": "23264632"
      },
      "source": [
        "<b>Exercise</b>: How did the DAE denoise the samples from the classes that were excluded from the training? Why do you think that happened?  <br>\n",
        "<b>Answer</b>: Please type your answer here.....\n",
        "\n",
        "<b>Exercise</b>: Build a function that draws reconstruction loss for all the labels from the test set. We have already done that with the train data in the code above. Do the same thing on test data, this time instead of bunch of numbers, do it per class and plot the reconstruction error. Simply take MSE between the denoised image and the actual image. Use the `add_noise` function that we provided above. Also check `test_dae` function for more hints on calculating the loss. You can even write your custom MSE!.\n",
        "- Use `Subset` on test data for each class\n",
        "- denoise the images from the class\n",
        "- Calculate the error for each class\n",
        "- Plot the values for all 10 classes"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}